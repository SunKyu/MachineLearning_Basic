{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 28 16:20:48 2017\n",
    "\n",
    "@author: moonsooyoung\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import PIL.Image as pilimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#학습시킬 MNIST 숫자데이터를 부름.\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DeepNeuralNetwork에 쓸 각 layer에 사용할 노드의 갯수를 사용자가 원하는 만큼 정해줌.\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "\n",
    "#n_classes = 데이터의 클래스 수. MNIST에서는 0,1,2,3,4,5,6,7,8,9 총 10개.\n",
    "n_classes = 10\n",
    "\n",
    "#batch_size를 원하는 만큼 정해줌.\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input과 output의 placeholder을 만들어줌. [None, 784]는 input data의 사이즈.\n",
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "#신경망 구조에 들어갈 변수를 정의해줌. 훈련 전에는 랜덤한 값을 임의로 넣어 초기값을 잡아줌.\n",
    "#y=XW+b 임을 고려하여 벡터크기를 지정해줌.\n",
    "w1 = tf.Variable(tf.random_normal([784, n_nodes_hl1]))\n",
    "b1 = tf.Variable(tf.random_normal([n_nodes_hl1]))\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2]))\n",
    "b2 = tf.Variable(tf.random_normal([n_nodes_hl2]))\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3]))\n",
    "b3 = tf.Variable(tf.random_normal([n_nodes_hl3]))\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([n_nodes_hl3, n_classes]))\n",
    "b4 = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#신경망 구조\n",
    "l1 = tf.add(tf.matmul(x,w1), b1)\n",
    "l1 = tf.nn.relu(l1)\n",
    "\n",
    "l2 = tf.add(tf.matmul(l1,w2), b2)\n",
    "l2 = tf.nn.relu(l2)\n",
    "\n",
    "l3 = tf.add(tf.matmul(l2,w3), b3)\n",
    "l3 = tf.nn.relu(l3)\n",
    "\n",
    "output = tf.matmul(l3,w4) + b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#변수들을 저장해줄 파일경로를 지정해줌.\n",
    "save_path = 'machine/'\n",
    "model_name = 'DNN_md'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "save_path_full = os.path.join(save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 5 loss: 1622345.8783\n",
      "Epoch 1 completed out of 5 loss: 385332.328979\n",
      "Epoch 2 completed out of 5 loss: 214236.015845\n",
      "Epoch 3 completed out of 5 loss: 127034.356157\n",
      "Epoch 4 completed out of 5 loss: 78192.3934943\n",
      "Accuracy: 0.9398\n"
     ]
    }
   ],
   "source": [
    "#학습 단계 알고리즘\n",
    "def train_neural_network(x):\n",
    "    prediction = output\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\n",
    "    learning_rate=0.001\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    hm_epochs = 5\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                sess.run(l1, feed_dict={x: epoch_x})\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "        #아까 지정한 파일경로로 변수들을 저장해줌. 지정할 변수를 리스트 형태로 써줌.\n",
    "        saver = tf.train.Saver([w1, w2, w3, w4, b1, b2, b3, b4])\n",
    "        saver.save(sess,save_path_full)    #자신이 지정해준 파일에 .meta형식의 파일이 생김.\n",
    "        \n",
    "#학습 시작\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 단계\n",
    "#테스트할 파일을 불러옴.\n",
    "k = pilimg.open('/Volumes/SM/seven.png' )\n",
    "plt.imshow(k)\n",
    "imgarray=np.array(k)    #컬러채널이 1개가 되도록 이미 전처리를 한 상태라서 그냥 (28,28)로 나옴.\n",
    "kkk = imgarray/255    #k1 벡터 안의 숫자들을 0과 1 사이로 normalize시키기 벡터 내의 가장 큰 값으로 k1을 나눠줌.\n",
    "sydata=kkk.reshape(1,784)    #훈련할 때와 같은 input data 형태로 맞춰줌. (28,28)->(1,784).\n",
    "x_data = tf.cast(sydata, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from machine/DNN_md\n"
     ]
    }
   ],
   "source": [
    "#변수 불러오기\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver([w1, w2, w3, w4, b1, b2, b3, b4])    #전에 저장해둔 변수를 불러옴.\n",
    "new_saver = tf.train.import_meta_graph('/Volumes/SM/DNN/machine/DNN_md.meta')    \n",
    "#학습 단계에서 자동으로 생긴 meta file에 변수들의 값이 저장되어 있음. saver.restore()로 그 값들을 불러옴.\n",
    "saver.restore(sess,save_path_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#처음에 썼던 신경망 알고리즘을 그대로 써주고, input data넣는 x자리에 테스트 할 데이터(x_data)를 바꿔 써줌.\n",
    "l1 = tf.add(tf.matmul(x_data,w1), b1)\n",
    "l1 = tf.nn.relu(l1)\n",
    "\n",
    "l2 = tf.add(tf.matmul(l1,w2), b2)\n",
    "l2 = tf.nn.relu(l2)\n",
    "\n",
    "l3 = tf.add(tf.matmul(l2,w3), b3)\n",
    "l3 = tf.nn.relu(l3)\n",
    "\n",
    "output = tf.matmul(l3,w4) + b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================TEST 결과============================================\n",
      "[[ -1691.77246094  -9482.28320312   7775.19384766  13715.46289062\n",
      "   -4566.18164062  -9743.04394531 -28360.29492188  23831.29882812\n",
      "   10846.51367188   4017.27563477]]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "#테스트 시작\n",
    "print('============================================TEST 결과============================================')\n",
    "print(sess.run (output))\n",
    "print(sess.run(tf.argmax(output, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
